{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwHPatIY9xbs"
      },
      "outputs": [],
      "source": [
        "pip install transformers datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv(\"/content/drive/MyDrive/Movie_Dataset.csv\")\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "YE-SQuB2_am7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"sentiment\"].value_counts()"
      ],
      "metadata": {
        "id": "9UqfN0zWBD7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import matplotlib as mpl\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#this prevents matplotlib from parsing $ as math\n",
        "mpl.rcParams[\"text.usetex\"] = False\n",
        "mpl.rcParams[\"text.parse_math\"] = False\n",
        "\n",
        "TEXT_COL = \"review\"\n",
        "\n",
        "# word count\n",
        "df[\"word_count\"] = df[TEXT_COL].apply(lambda x: len(re.findall(r\"\\b\\w+\\b\", x)))\n",
        "\n",
        "# histogram\n",
        "plt.figure(figsize=(7,4))\n",
        "plt.hist(df[\"word_count\"], bins=50)\n",
        "plt.axvline(512, linestyle=\"--\")  # BERT token limit shall be 512\n",
        "plt.xlabel(\"Word count\")\n",
        "plt.ylabel(\"Number of reviews\")\n",
        "plt.title(\"Review Length Distribution (Words)\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qfFbFiEoB_XJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    Clean text by removing HTML tags and URLs while preserving:\n",
        "    - Stop words\n",
        "    - Punctuation\n",
        "    - Sentence structure\n",
        "    \"\"\"\n",
        "    # Ensure text is a string\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "\n",
        "    # Remove HTML tags (<br />)\n",
        "    text = re.sub(r'<.*?>', ' ', text)\n",
        "\n",
        "    # Remove URLs (http/https links)\n",
        "    text = re.sub(r'http\\S+|www\\.\\S+', '', text)\n",
        "\n",
        "    # Remove Twitter handles (if any)\n",
        "    text = re.sub(r'@\\w+', '', text)\n",
        "\n",
        "    # Remove extra whitespace (multiple spaces, tabs, newlines)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "\n",
        "    # Strip leading/trailing whitespace\n",
        "    text = text.strip()\n",
        "\n",
        "    return text\n",
        "\n",
        "# Apply cleaning\n",
        "df['cleaned_review'] = df['review'].apply(clean_text)\n",
        "\n",
        "# Verify\n",
        "print(\"First cleaned review:\")\n",
        "print(df['cleaned_review'].iloc[0][:300])"
      ],
      "metadata": {
        "id": "cEwN22IvoAi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "import torch\n",
        "\n",
        "# Load the BERT tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Set maximum length\n",
        "MAX_LENGTH = 512\n",
        "\n",
        "# Tokenize the cleaned reviews\n",
        "def tokenize_data(texts, labels):\n",
        "    \"\"\"\n",
        "    Tokenize text data for BERT\n",
        "    Returns: input_ids, attention_mask, labels\n",
        "    \"\"\"\n",
        "    encodings = tokenizer(\n",
        "        texts.tolist(),\n",
        "        truncation=True,           # Truncate sequences longer than max_length\n",
        "        padding='max_length',      # Pad sequences shorter than max_length\n",
        "        max_length=MAX_LENGTH,\n",
        "        return_tensors='pt'        # Return PyTorch tensors\n",
        "    )\n",
        "\n",
        "    return encodings\n",
        "\n",
        "# Convert sentiment labels to numbers (0 = negative, 1 = positive)\n",
        "df['label'] = df['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)\n",
        "\n",
        "# Tokenize the data\n",
        "encodings = tokenize_data(df['cleaned_review'], df['label'])\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"TOKENIZATION COMPLETE!\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\nShape of input_ids: {encodings['input_ids'].shape}\")\n",
        "print(f\"Shape of attention_mask: {encodings['attention_mask'].shape}\")\n",
        "print(f\"\\nNumber of samples: {encodings['input_ids'].shape[0]}\")\n",
        "print(f\"Max sequence length: {encodings['input_ids'].shape[1]}\")\n",
        "\n",
        "# Show an example (checked with claude)\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"EXAMPLE - First Review:\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\nOriginal text (first 200 chars):\\n{df['cleaned_review'].iloc[0][:200]}\")\n",
        "print(f\"\\nInput IDs (first 20 tokens):\\n{encodings['input_ids'][0][:20]}\")\n",
        "print(f\"\\nAttention Mask (first 20 tokens):\\n{encodings['attention_mask'][0][:20]}\")\n",
        "print(f\"\\nLabel: {df['label'].iloc[0]} ({df['sentiment'].iloc[0]})\")\n",
        "\n",
        "# Decode tokens back to text to see how tokenization works\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"TOKENIZATION BREAKDOWN (First 30 tokens):\")\n",
        "print(\"=\" * 80)\n",
        "tokens = tokenizer.convert_ids_to_tokens(encodings['input_ids'][0][:30])\n",
        "for i, token in enumerate(tokens):\n",
        "    print(f\"{i}: {token}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mTWoZrkVCHDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "import torch\n",
        "\n",
        "# Load pre-trained BERT model for binary classification\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    'bert-base-uncased',\n",
        "    num_labels=2,  # Binary classification: positive/negative\n",
        "    output_attentions=False,\n",
        "    output_hidden_states=False\n",
        ")\n",
        "\n",
        "\n",
        "print(\"MODEL LOADED SUCCESSFULLY!\")\n",
        "\n",
        "\n",
        "# Check total parameters\n",
        "total_params=sum(p.numel() for p in model.parameters())\n",
        "print(f\"\\nTotal parameters: {total_params:,}\")\n",
        "\n",
        "# Freeze early layers (we'll freeze all except the last 2 transformer layers + classifier)\n",
        "print(\"FREEZING EARLY LAYERS...\")\n",
        "\n",
        "# Freeze embeddings\n",
        "for param in model.bert.embeddings.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Freeze first 10 encoder layers (keep last 2 unfrozen)\n",
        "for layer in model.bert.encoder.layer[:10]:\n",
        "    for param in layer.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "# Count trainable vs frozen parameters\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "frozen_params = sum(p.numel() for p in model.parameters() if not p.requires_grad)\n",
        "\n",
        "print(f\"\\nTotal parameters: {total_params:,}\")\n",
        "print(f\"Trainable parameters: {trainable_params:,}\")\n",
        "print(f\"Frozen parameters: {frozen_params:,}\")\n",
        "print(f\"Percentage trainable: {100 * trainable_params / total_params:.2f}%\")\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(f\"MODEL MOVED TO: {device}\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "if device.type == 'cuda':\n",
        "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "else:\n",
        "    print(\"⚠️ WARNING: Running on CPU - Training will be VERY slow!\")\n",
        "    print(\"Please switch to GPU runtime in Colab: Runtime → Change runtime type → GPU\")\n",
        "\n"
      ],
      "metadata": {
        "id": "PW6R1Z1EFGn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import  get_linear_schedule_with_warmup\n",
        "from torch.optim import AdamW\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# STEP 1: SPLIT DATA (80% train, 10% validation, 10% test)\n",
        "\n",
        "print(\"SPLITTING DATA...\")\n",
        "\n",
        "# Get input_ids, attention_mask, and labels\n",
        "input_ids = encodings['input_ids']\n",
        "attention_mask = encodings['attention_mask']\n",
        "labels = torch.tensor(df['label'].values)\n",
        "\n",
        "# First split: 80% train, 20% temp (which will become 10% val + 10% test)\n",
        "train_inputs, temp_inputs, train_masks, temp_masks, train_labels, temp_labels = train_test_split(\n",
        "    input_ids, attention_mask, labels,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=labels  # Ensures balanced splits\n",
        ")\n",
        "\n",
        "# Second split: Split temp into 50% validation and 50% test (10% each of total)\n",
        "val_inputs, test_inputs, val_masks, test_masks, val_labels, test_labels = train_test_split(\n",
        "    temp_inputs, temp_masks, temp_labels,\n",
        "    test_size=0.5,\n",
        "    random_state=42,\n",
        "    stratify=temp_labels\n",
        ")\n",
        "\n",
        "print(f\"Training samples: {len(train_labels)}\")\n",
        "print(f\"Validation samples: {len(val_labels)}\")\n",
        "print(f\"Test samples: {len(test_labels)}\")\n",
        "\n",
        "\n",
        "# STEP 2: CREATE DATALOADERS\n",
        "\n",
        "print(\"CREATING DATALOADERS...\")\n",
        "\n",
        "\n",
        "BATCH_SIZE = 16  # Use 16 or 32 depending on GPU memory\n",
        "\n",
        "# Create TensorDatasets\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_dataloader = DataLoader(\n",
        "    train_data,\n",
        "    sampler=RandomSampler(train_data),\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "val_dataloader = DataLoader(\n",
        "    val_data,\n",
        "    sampler=SequentialSampler(val_data),\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    test_data,\n",
        "    sampler=SequentialSampler(test_data),\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "print(f\"Batch size: {BATCH_SIZE}\")\n",
        "print(f\"Training batches: {len(train_dataloader)}\")\n",
        "print(f\"Validation batches: {len(val_dataloader)}\")\n",
        "print(f\"Test batches: {len(test_dataloader)}\")\n",
        "\n",
        "# STEP 3: SETUP OPTIMIZER AND SCHEDULER\n",
        "\n",
        "print(\"SETTING UP OPTIMIZER...\")\n",
        "\n",
        "EPOCHS = 3\n",
        "LEARNING_RATE = 2e-5\n",
        "\n",
        "# AdamW optimizer\n",
        "optimizer = AdamW(\n",
        "    model.parameters(),\n",
        "    lr=LEARNING_RATE,\n",
        "    eps=1e-8\n",
        ")\n",
        "\n",
        "# Learning rate scheduler with warmup\n",
        "total_steps = len(train_dataloader) * EPOCHS\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "print(f\"Optimizer: AdamW\")\n",
        "print(f\"Learning rate: {LEARNING_RATE}\")\n",
        "print(f\"Epochs: {EPOCHS}\")\n",
        "print(f\"Total training steps: {total_steps}\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 4: TRAINING LOOP\n",
        "# ============================================================================\n",
        "\n",
        "print(\"STARTING TRAINING...\")\n",
        "\n",
        "# Store training statistics\n",
        "training_stats = []\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"\\n{'=' * 80}\")\n",
        "    print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n",
        "    print('=' * 80)\n",
        "\n",
        "    # ========================================\n",
        "    # Training\n",
        "    # ========================================\n",
        "    model.train()\n",
        "\n",
        "    total_train_loss = 0\n",
        "    train_start_time = time.time()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # Progress update every 50 batches\n",
        "        if step % 50 == 0 and step != 0:\n",
        "            elapsed = time.time() - train_start_time\n",
        "            print(f\"  Batch {step}/{len(train_dataloader)} | Elapsed: {elapsed:.2f}s\")\n",
        "\n",
        "        # Move batch to GPU\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Clear gradients\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(\n",
        "            b_input_ids,\n",
        "            attention_mask=b_input_mask,\n",
        "            labels=b_labels\n",
        "        )\n",
        "\n",
        "        loss = outputs.loss\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Backward pass (for differentiation)\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip gradients to prevent exploding gradients\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate average training loss\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "    training_time = time.time() - train_start_time\n",
        "\n",
        "    print(f\"\\n  Average training loss: {avg_train_loss:.4f}\")\n",
        "    print(f\"  Training time: {training_time:.2f}s\")\n",
        "\n",
        "    # ========================================\n",
        "    # Validation\n",
        "    # ========================================\n",
        "    print(f\"\\n  Running Validation...\")\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    total_val_loss = 0\n",
        "    total_val_accuracy = 0\n",
        "\n",
        "    for batch in val_dataloader:\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # No gradient calculation for validation\n",
        "        with torch.no_grad():\n",
        "            outputs = model(\n",
        "                b_input_ids,\n",
        "                attention_mask=b_input_mask,\n",
        "                labels=b_labels\n",
        "            )\n",
        "\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "\n",
        "        total_val_loss += loss.item()\n",
        "\n",
        "        # Calculate accuracy\n",
        "        preds = torch.argmax(logits, dim=1).flatten()\n",
        "        accuracy = (preds == b_labels).cpu().numpy().mean()\n",
        "        total_val_accuracy += accuracy\n",
        "\n",
        "    avg_val_loss = total_val_loss / len(val_dataloader)\n",
        "    avg_val_accuracy = total_val_accuracy / len(val_dataloader)\n",
        "\n",
        "    print(f\"  Validation Loss: {avg_val_loss:.4f}\")\n",
        "    print(f\"  Validation Accuracy: {avg_val_accuracy:.4f}\")\n",
        "\n",
        "    # Store stats\n",
        "    training_stats.append({\n",
        "        'epoch': epoch + 1,\n",
        "        'train_loss': avg_train_loss,\n",
        "        'val_loss': avg_val_loss,\n",
        "        'val_accuracy': avg_val_accuracy,\n",
        "        'training_time': training_time\n",
        "    })\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"TRAINING COMPLETE!\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Display training summary\n",
        "print(\"\\nTraining Summary:\")\n",
        "for stat in training_stats:\n",
        "    print(f\"\\nEpoch {stat['epoch']}:\")\n",
        "    print(f\"  Train Loss: {stat['train_loss']:.4f}\")\n",
        "    print(f\"  Val Loss: {stat['val_loss']:.4f}\")\n",
        "    print(f\"  Val Accuracy: {stat['val_accuracy']:.4f}\")\n",
        "    print(f\"  Time: {stat['training_time']:.2f}s\")"
      ],
      "metadata": {
        "id": "7kDMTWHUFHev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 1: EVALUATE ON TEST SET\n",
        "# ============================================================================\n",
        "print(\"=\" * 80)\n",
        "print(\"EVALUATING ON TEST SET...\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "model.eval()\n",
        "\n",
        "predictions = []\n",
        "true_labels = []\n",
        "\n",
        "# Make predictions on test set\n",
        "for batch in test_dataloader:\n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(\n",
        "            b_input_ids,\n",
        "            attention_mask=b_input_mask\n",
        "        )\n",
        "\n",
        "    logits = outputs.logits\n",
        "    preds = torch.argmax(logits, dim=1).flatten()\n",
        "\n",
        "    predictions.extend(preds.cpu().numpy())\n",
        "    true_labels.extend(b_labels.cpu().numpy())\n",
        "\n",
        "# Convert to numpy arrays\n",
        "predictions = np.array(predictions)\n",
        "true_labels = np.array(true_labels)\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 2: CALCULATE METRICS\n",
        "# ============================================================================\n",
        "accuracy = accuracy_score(true_labels, predictions)\n",
        "f1 = f1_score(true_labels, predictions, average='binary')\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"TEST SET RESULTS\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\nAccuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"DETAILED CLASSIFICATION REPORT\")\n",
        "print(\"=\" * 80)\n",
        "print(classification_report(true_labels, predictions, target_names=['Negative', 'Positive']))\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 3: CONFUSION MATRIX\n",
        "# ============================================================================\n",
        "cm = confusion_matrix(true_labels, predictions)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Negative', 'Positive'],\n",
        "            yticklabels=['Negative', 'Positive'])\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(f\"True Negatives: {cm[0][0]}\")\n",
        "print(f\"False Positives: {cm[0][1]}\")\n",
        "print(f\"False Negatives: {cm[1][0]}\")\n",
        "print(f\"True Positives: {cm[1][1]}\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 4: INFERENCE PIPELINE\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"CREATING INFERENCE PIPELINE...\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "def predict_sentiment(text, model, tokenizer, device, max_length=512):\n",
        "    \"\"\"\n",
        "    Predict sentiment for a single text input\n",
        "\n",
        "    Args:\n",
        "        text: Raw text string\n",
        "        model: Trained BERT model\n",
        "        tokenizer: BERT tokenizer\n",
        "        device: GPU/CPU device\n",
        "        max_length: Maximum sequence length\n",
        "\n",
        "    Returns:\n",
        "        sentiment: 'Positive' or 'Negative'\n",
        "        confidence: Confidence score (0-1)\n",
        "    \"\"\"\n",
        "    # Clean the text (same cleaning as training)\n",
        "    text = clean_text(text)\n",
        "\n",
        "    # Tokenize\n",
        "    encoding = tokenizer(\n",
        "        text,\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        max_length=max_length,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    # Move to device\n",
        "    input_ids = encoding['input_ids'].to(device)\n",
        "    attention_mask = encoding['attention_mask'].to(device)\n",
        "\n",
        "    # Predict\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "\n",
        "    # Get probabilities using softmax\n",
        "    probabilities = torch.nn.functional.softmax(logits, dim=1)\n",
        "    confidence, predicted_class = torch.max(probabilities, dim=1)\n",
        "\n",
        "    # Convert to readable format\n",
        "    sentiment = 'Positive' if predicted_class.item() == 1 else 'Negative'\n",
        "    confidence_score = confidence.item()\n",
        "\n",
        "    return sentiment, confidence_score, probabilities[0].cpu().numpy()\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 5: TEST INFERENCE WITH EXAMPLES\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"TESTING INFERENCE PIPELINE\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Test examples\n",
        "test_examples = [\n",
        "    \"The cinematography was great but the plot was boring\",\n",
        "    \"This movie was absolutely amazing! Best film I've seen all year!\",\n",
        "    \"Terrible acting and a waste of time. Do not watch this.\",\n",
        "    \"It was okay, nothing special but not terrible either.\",\n",
        "    \"I loved every minute of it! The characters were so well developed.\",\n",
        "    \"Worst movie ever made. Complete garbage.\"\n",
        "]\n",
        "\n",
        "print(\"\\nPredictions:\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "for i, example in enumerate(test_examples, 1):\n",
        "    sentiment, confidence, probs = predict_sentiment(example, model, tokenizer, device)\n",
        "\n",
        "    print(f\"\\n{i}. Text: \\\"{example}\\\"\")\n",
        "    print(f\"   Prediction: {sentiment}\")\n",
        "    print(f\"   Confidence: {confidence:.4f} ({confidence*100:.2f}%)\")\n",
        "    print(f\"   Probabilities - Negative: {probs[0]:.4f}, Positive: {probs[1]:.4f}\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 6: INTERACTIVE PREDICTION FUNCTION\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"INFERENCE PIPELINE READY!\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\\nYou can now use the predict_sentiment() function for any text:\")\n",
        "print(\"\\nExample usage:\")\n",
        "print(\"sentiment, confidence, probs = predict_sentiment('Your text here', model, tokenizer, device)\")\n",
        "print(\"print(f'Sentiment: {sentiment} (Confidence: {confidence:.2%})')\")\n",
        "\n",
        "# Save the function for easy use\n",
        "def analyze_review(review_text):\n",
        "    \"\"\"Easy-to-use wrapper function\"\"\"\n",
        "    sentiment, confidence, probs = predict_sentiment(review_text, model, tokenizer, device)\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Review: {review_text}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Sentiment: {sentiment}\")\n",
        "    print(f\"Confidence: {confidence*100:.2f}%\")\n",
        "    print(f\"Negative probability: {probs[0]*100:.2f}%\")\n",
        "    print(f\"Positive probability: {probs[1]*100:.2f}%\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    return sentiment, confidence\n",
        "\n",
        "print(\"\\n✓ Use analyze_review('your text') for quick predictions!\")"
      ],
      "metadata": {
        "id": "H-HRg34zFasA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "34u3-mD4KOon"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}